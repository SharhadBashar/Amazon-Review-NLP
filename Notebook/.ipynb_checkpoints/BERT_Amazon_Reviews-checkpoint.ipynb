{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 63
    },
    "colab_type": "code",
    "id": "UFT54wV52BDF",
    "outputId": "5b9bee61-1ff0-4adb-b637-603f09d1b2ba"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import  BertModel, BertTokenizer\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import os\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K_Hkph5m5s3a"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4n3kKqRm2LcI"
   },
   "outputs": [],
   "source": [
    "def read_and_shuffle(file):\n",
    "    df = pd.read_csv(file)\n",
    "    # Random shuffle.\n",
    "    df.sample(frac = 1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oerGzXhG2Qjq"
   },
   "outputs": [],
   "source": [
    "def get_train_and_val_split(df, splitRatio = 0.8):\n",
    "    train = df.sample(frac = splitRatio, random_state = 200)\n",
    "    val = df.drop(train.index)\n",
    "    print('Number of Training Samples: ', len(train))\n",
    "    print('Number of Validation Samples: ', len(val))\n",
    "    return(train, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9naLmqgV2Sfl"
   },
   "outputs": [],
   "source": [
    "def get_max_length(reviews):\n",
    "    return len(max(reviews, key = len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ruXknayR2VDa"
   },
   "outputs": [],
   "source": [
    "def get_accuracy(logits, labels):\n",
    "    # get the index of the max value in the row.\n",
    "    predictedClass = logits.max(dim = 1)[1]\n",
    "\n",
    "    # get accuracy by averaging over entire batch.\n",
    "    acc = (predictedClass == labels).float().mean()\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-vBprhKJ2ZVb"
   },
   "outputs": [],
   "source": [
    "def trainFunc(net, loss_func, opti, train_loader, test_loader, config):\n",
    "    best_acc = 0\n",
    "    for ep in range(config[\"epochs\"]):\n",
    "        for it, (seq, attn_masks, labels) in enumerate(train_loader):\n",
    "            opti.zero_grad()\n",
    "            #seq, attn_masks, labels = seq.cuda(args.gpu), attn_masks.cuda(args.gpu), labels.cuda(args.gpu)\n",
    "            seq, attn_masks, labels = seq.to(device), attn_masks.to(device), labels.to(device)\n",
    "\n",
    "            logits = net(seq, attn_masks)\n",
    "            loss = loss_func(m(logits), labels)\n",
    "\n",
    "            loss.backward()\n",
    "            opti.step()\n",
    "            print(\"Iteration: \", it+1)\n",
    "\n",
    "            if (it + 1) % config[\"printEvery\"] == 0:\n",
    "                acc = get_accuracy(m(logits), labels)\n",
    "                if not os.path.exists(config[\"outputFolder\"]):\n",
    "                    os.makedirs(config[\"outputFolder\"])\n",
    "\n",
    "                # Since a single epoch could take well over hours, we regularly save the model even during evaluation of training accuracy.\n",
    "                torch.save(net.state_dict(), os.path.join(projectFolder, config[\"outputFolder\"], config[\"outputFileName\"]))\n",
    "                print(\"Iteration {} of epoch {} complete. Loss : {} Accuracy : {}\".format(it+1, ep+1, loss.item(), acc))\n",
    "                print(\"Saving at\", os.path.join(projectFolder, config[\"outputFolder\"], config[\"outputFileName\"]))\n",
    "\n",
    "        # perform validation at the end of an epoch.\n",
    "        val_acc, val_loss = evaluate(net, loss_func, val_loader, config)\n",
    "        print(\" Validation Accuracy : {}, Validation Loss : {}\".format(val_acc, val_loss))\n",
    "        if val_acc > best_acc:\n",
    "            print(\"Best validation accuracy improved from {} to {}, saving model...\".format(best_acc, val_acc))\n",
    "            best_acc = val_acc\n",
    "            torch.save(net.state_dict(), os.path.join(projectFolder, config[\"outputFolder\"], config[\"outputFileName\"] + \"_valTested_\" + str(best_acc)))\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TSIptpqP2fRo"
   },
   "outputs": [],
   "source": [
    "def evaluate(net, loss_func, dataloader, config):\n",
    "    net.eval()\n",
    "\n",
    "    mean_acc, mean_loss = 0, 0\n",
    "    count = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for seq, attn_masks, labels in dataloader:\n",
    "            #seq, attn_masks, labels = seq.cuda(args.gpu), attn_masks.cuda(args.gpu), labels.cuda(args.gpu)\n",
    "            seq, attn_masks, labels = seq.to(device), attn_masks.to(device), labels.to(device)\n",
    "\n",
    "            logits = net(seq, attn_masks)\n",
    "            mean_loss += loss_func(m(logits), labels)\n",
    "            mean_acc += get_accuracy(m(logits), labels)\n",
    "            print(\"Validation iteration\", count+1)\n",
    "            count += 1\n",
    "\n",
    "            '''\n",
    "            The entire validation set was around 0.1 million entries,\n",
    "            the validationFraction param controls what fraction of the shuffled\n",
    "            validation set you want to validate the results on.\n",
    "            '''\n",
    "            if count > config[\"validationFraction\"] * len(val_set):\n",
    "                break\n",
    "    return mean_acc / count, mean_loss / count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ljqzMJFn2mV4"
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"splitRatio\" : 0.8,\n",
    "    \"maxLength\" : 100,\n",
    "    \"printEvery\" : 100,\n",
    "    \"outputFolder\" : \"Models\",\n",
    "    \"outputFileName\" : \"AmazonReviewClassifier.dat\",\n",
    "    \"threads\" : 4,\n",
    "    \"batchSize\" : 64,\n",
    "    \"validationFraction\" : 0.0005,\n",
    "    \"epochs\" : 5,\n",
    "    \"forceCPU\" : True\n",
    "    }\n",
    "if config[\"forceCPU\"]:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "config[\"device\"] = device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UhyAAjcB2xqR"
   },
   "outputs": [],
   "source": [
    "class SentimentClassifier(nn.Module):\n",
    "    def __init__(self, num_classes, device, freeze_bert = True):\n",
    "        super(SentimentClassifier, self).__init__()\n",
    "        self.bert_layer = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.device = device\n",
    "\n",
    "        if freeze_bert:\n",
    "            for p in self.bert_layer.parameters():\n",
    "                p.requires_grad = False\n",
    "\n",
    "        self.cls_layer = nn.Linear(768, num_classes)\n",
    "\n",
    "    def forward(self, seq, attn_masks):\n",
    "        '''\n",
    "        Inputs:\n",
    "            -seq : Tensor of shape [B, T] containing token ids of sequences\n",
    "            -attn_masks : Tensor of shape [B, T] containing attention masks to be used to avoid contibution of PAD tokens\n",
    "        '''\n",
    "\n",
    "        #Feeding the input to BERT model to obtain contextualized representations\n",
    "        cont_reps, _ = self.bert_layer(seq, attention_mask = attn_masks)\n",
    "\n",
    "        #Obtaining the representation of [CLS] head\n",
    "        cls_rep = cont_reps[:, 0]\n",
    "\n",
    "        #Feeding cls_rep to the classifier layer\n",
    "        logits = self.cls_layer(cls_rep)\n",
    "\n",
    "        return logits.to(self.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "znUMPleM24mj"
   },
   "outputs": [],
   "source": [
    "class AmazonReviewsDataset(Dataset):\n",
    "    def __init__(self, df, maxlen):\n",
    "        self.df = df\n",
    "        # A reset reindexes from 1 to len(df), the shuffled df frames are sparse.\n",
    "        self.df.reset_index(drop=True, inplace=True)\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "        self.maxlen = maxlen\n",
    "\n",
    "    def __len__(self):\n",
    "        return(len(self.df))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        review = self.df.loc[index, 'Text']\n",
    "\n",
    "        # Classes start from 0.\n",
    "        label = int(self.df.loc[index, 'Score']) - 1\n",
    "\n",
    "        # Use BERT tokenizer since it needs to be able to match the tokens to the pre trained words.\n",
    "        tokens = self.tokenizer.tokenize(review)\n",
    "\n",
    "        # BERT inputs typically start with a '[CLS]' tag and end with a '[SEP]' tag. For\n",
    "        tokens = ['[CLS]'] + tokens + ['[SEP]']\n",
    "\n",
    "        if len(tokens) < self.maxlen:\n",
    "            # Add the ['PAD'] token\n",
    "            tokens = tokens + ['[PAD]' for item in range(self.maxlen-len(tokens))]\n",
    "        else:\n",
    "            # Truncate the tokens at maxLen - 1 and add a '[SEP]' tag.\n",
    "            tokens = tokens[:self.maxlen-1] + ['[SEP]']\n",
    "\n",
    "        # BERT tokenizer converts the string tokens to their respective IDs.\n",
    "        token_ids = self.tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "        # Converting to pytorch tensors.\n",
    "        tokens_ids_tensor = torch.tensor(token_ids)\n",
    "\n",
    "        # Masks place a 1 if token != PAD else a 0.\n",
    "        attn_mask = (tokens_ids_tensor != 0).long()\n",
    "        \n",
    "        return tokens_ids_tensor, attn_mask, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "s6qMODHX3MQ0",
    "outputId": "4346c388-4e60-4d17-b43a-a6e771bff6d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT tokenizer...\n",
      "Configuration is:  {'splitRatio': 0.8, 'maxLength': 100, 'printEvery': 100, 'outputFolder': 'Models', 'outputFileName': 'AmazonReviewClassifier.dat', 'threads': 4, 'batchSize': 64, 'validationFraction': 0.0005, 'epochs': 5, 'forceCPU': True, 'device': device(type='cpu')}\n"
     ]
    }
   ],
   "source": [
    "print('Loading BERT tokenizer...')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case = True)\n",
    "\n",
    "print(\"Configuration is: \", config)\n",
    "# Read and shuffle input data.\n",
    "df = read_and_shuffle('../dataset/sample_us.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "jYyvxXRR3ceK",
    "outputId": "fafce265-0510-4f6d-f4fd-777c5454397e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Target Output Classes: 5\n"
     ]
    }
   ],
   "source": [
    "num_classes = df['star_rating'].nunique()\n",
    "print('Number of Target Output Classes:', num_classes)\n",
    "totalDatasetSize = len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8P6nDjzD3hCh"
   },
   "outputs": [],
   "source": [
    "# Group by the column Score. This helps you get distribution of the Review Scores.\n",
    "symbols = df.groupby('star_rating')\n",
    "\n",
    "scores_dist = []\n",
    "for i in range(num_classes):\n",
    "    scores_dist.append(len(symbols.groups[i + 1]) / totalDatasetSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "7nmoAHec3mnP",
    "outputId": "f1c754cd-3b93-42c8-e437-2c45762ffa40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Training Samples:  39\n",
      "Number of Validation Samples:  10\n"
     ]
    }
   ],
   "source": [
    "train, val = get_train_and_val_split(df, config['splitRatio'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DKdvSrplWUpH"
   },
   "outputs": [],
   "source": [
    "val.to_csv('../dataset/Validations.csv')\n",
    "train.to_csv('../dataset/Train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6PQMMnpz3ptw"
   },
   "outputs": [],
   "source": [
    "# You can set the length to the true max length from the dataset, I have reduced it for the sake of memory and quicker training.\n",
    "#T = get_max_length(reviews)\n",
    "T = config['maxLength']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wA2kwsot3tkz"
   },
   "outputs": [],
   "source": [
    "train_set = AmazonReviewsDataset(train, T)\n",
    "val_set = AmazonReviewsDataset(val, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0MbfDj7w31p-"
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, batch_size = config['batchSize'], num_workers = config['threads'])\n",
    "val_loader = DataLoader(val_set, batch_size = config['batchSize'], num_workers = config['threads'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t0gR6VMY39FG"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# We are unfreezing the BERT layers so as to be able to fine tune and save a new BERT model that is specific to the Sizeable food reviews dataset.\n",
    "\n",
    "net = SentimentClassifier(num_classes, config['device'], freeze_bert=False)\n",
    "net.to(config['device'])\n",
    "weights = torch.tensor(scores_dist).to(config['device'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UP5uo4sf4MxK"
   },
   "outputs": [],
   "source": [
    "# Setting the Loss function and Optimizer.\n",
    "loss_func = nn.NLLLoss(weight=weights)\n",
    "opti = optim.Adam(net.parameters(), lr = 2e-5)\n",
    "m = nn.LogSoftmax(dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "NfvnHnNW4SRZ",
    "outputId": "c44cec3f-cdb5-4a7e-8c4b-fcc25f9b9613",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# torch.cuda.set_device(0)\n",
    "trainFunc(net, loss_func, opti, train_loader, val_loader, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "BERT_Amazon_Reviews",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
